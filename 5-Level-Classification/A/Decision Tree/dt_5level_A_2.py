# -*- coding: utf-8 -*-
"""DT-Regression-por

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yWyqujxFENiK0V8aHE03biglMe_hILGd
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import graphviz
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
data = pd.read_csv('student-por.csv', sep=';')

# Create the 5-class target variable based on G3
data['G3_class'] = pd.cut(
    data['G3'],
    bins=[0, 9, 11, 13, 15, 20],
    labels=['Fail', 'Sufficient', 'Satisfactory', 'Good', 'Excellent'],
    right=False
)

# Encode categorical variables as numeric
data_encoded = pd.get_dummies(data, drop_first=True)

# Define features (all features + G1 + G2) and target
features = list(data_encoded.columns)
features = [f for f in features if not f.startswith('G3_class')]  # Exclude G3_class columns
features.remove('G3')  # Exclude the original G3
X = data_encoded[features]  # Include all features (with G1 and G2)
y = data['G3_class']  # Use G3_class as the target variable

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Decision Tree Classifier
classifier = DecisionTreeClassifier(random_state=42, max_depth=3)  # Start with max_depth=3
classifier.fit(X_train, y_train)

# Make predictions
y_pred = classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')  # Weighted-average for multi-class
recall = recall_score(y_test, y_pred, average='weighted')        # Weighted-average for multi-class
f1 = f1_score(y_test, y_pred, average='weighted')                # Weighted-average for multi-class

print(f"Accuracy: {accuracy:.2f}")
print(f"Precision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1-Score: {f1:.2f}")

# Print the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fail', 'Sufficient', 'Satisfactory', 'Good', 'Excellent'], yticklabels=['Fail', 'Sufficient', 'Satisfactory', 'Good', 'Excellent'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Visualize the decision tree
dot_data = export_graphviz(
    classifier,
    out_file=None,
    feature_names=features,
    class_names=['Fail', 'Sufficient', 'Satisfactory', 'Good', 'Excellent'],
    filled=True,
    rounded=True,
    special_characters=True
)
# graph = graphviz.Source(dot_data)
# graph.render("decision_tree_5_level_case_A", format="png", cleanup=True)
# print("5-Level classification decision tree visualization saved as 'decision_tree_5_level_case_A.png'.")

# print(f"Features for Task A: {list(X.columns)}")